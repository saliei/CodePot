{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This here is to keep main ideas while I go through [neuralnetworksanddeeplearning.com](http://neuralnetworksanddeeplearning.com) book, real quick in one day.\n",
    "\n",
    "* **perceptrons**: \n",
    "\n",
    "    * a **step function**\n",
    "    * by varying the **bias**(-threshold) we can achieve different set of decision making, regardless of weights.\n",
    "    * high(positive) bias means that it's very easy to make perceptron to fire, and vice versa:\n",
    "    $\\begin{eqnarray}\n",
    "  \\mbox{output} = \\left\\{ \n",
    "    \\begin{array}{ll} \n",
    "      0 & \\mbox{if } w\\cdot x + b \\leq 0 \\\\\n",
    "      1 & \\mbox{if } w\\cdot x + b > 0\n",
    "    \\end{array}\n",
    "  \\right.\n",
    "\\end{eqnarray}$\n",
    "\n",
    "    * you can use perceptrons to simulate a NAND gate, they are **unviersal for computation**, hence perceptrons are also universal for computation. you can use them to simulate any function! they are as good as any computing device. this is hardly a big news!\n",
    "    * BUT you can device *learning algorithms* that would lay out this \"circuts of gates\"(neural net with appropriate bias and weights) for you. this makes the difference.\n",
    "    * what would make learning possible(weights and bias) for the network is the property that small change in the weights and bias makes a small change in the output of the net.\n",
    "    * for a step function this is not possible, you need a smooth function **activation function**, hence **sigmoid** function.\n",
    "* **sigmoid neurons**:\n",
    "   \n",
    "    * sigmoid function $\\sigma(z)=\\frac{1}{1+\\exp(-z)}$\n",
    "    * can take real values instead of 1 and 0 for input and output\n",
    "    \n",
    "* **feed forward networks**: information is always fed forward, there is no loop. otherwise output will depend on the input. if there is loop it is called **recurrent neural network**, but looping is not instant, the ouput will be fed to input at some later time. \n",
    "\n",
    "* to determine the input layer dimension we look at the data dimesnion, e.g. for a $64\\times64$ grey scale image, the input layer is 4096 dimension with each value being the intensity of the pixel.\n",
    "\n",
    "* **segmentation problem** break up a sequence of numbers to stand alone numbers(images)\n",
    "* **cost function(loss function, objective function)**: an example: \n",
    "$\\begin{eqnarray}  C(w,b) \\equiv\n",
    "  \\frac{1}{2n} \\sum_x \\| y(x) - a\\|^2.\n",
    "\\end{eqnarray}$ *quadratic cost function* or *mean squared error*\n",
    "* **gradient descent** an algorithm to minimize cost function. you always want to have cost fucntion decreasing, so, $C:=C(\\vec\\nu), \\Rightarrow \\Delta C = \\nabla C\\cdot\\Delta\\nu$ so if we choose, $\\Delta\\nu = -\\eta\\nabla C$, $\\eta$ is **learning rate**. we will use this equation to update new positons(values), $\\nu^\\prime = \\nu - \\eta\\nabla C$, if learning rate is too big we have a problem with approximation, we may end up increasing cost function, if it's too small, it will take too much time to find the minimum. gradient descent update rule:\n",
    "$ w_k \\rightarrow w_k' = w_k-\\eta \\frac{\\partial C}{\\partial w_k} $ and  $ b_l \\rightarrow b_l' = b_l-\\eta \\frac{\\partial C}{\\partial b_l} $\n",
    "\n",
    "* cost function is an average over cost function for individual cost function over each training example. computing gradient over large training dataset would take much more time. hence **stochastic gradient descent**, the idea is to sample a random mini-batch over training example and use: \n",
    "$ \\begin{eqnarray}\n",
    "  \\frac{\\sum_{j=1}^m \\nabla C_{X_{j}}}{m} \\approx \\frac{\\sum_x \\nabla C_x}{n} = \\nabla C,\n",
    "\\end{eqnarray}$\n",
    "\n",
    "* stochastic gradient descent works by picking out a randomly chosen mini-batch of training inputs, and training with those. Then we pick out another randomly chosen mini-batch and train with those. And so on, until we've exhausted the training inputs, which is said to complete an epoch of training. At that point we start over with a new training epoch. if the batch size is one(like humans), then it is called *online* or *on-line* or incremental learning.\n",
    "\n",
    "* people use *validation* data to set *hyper-parameters* of the model, learning rate, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
